{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "---\n",
    "1. [Detecting Parkinson’s Disease with OpenCV, Computer Vision, and the Spiral/Wave Test](https://www.pyimagesearch.com/2019/04/29/detecting-parkinsons-disease-with-opencv-computer-vision-and-the-spiral-wave-test/)\n",
    "- [Distinguishing Different Stages of Parkinson’s Disease Using Composite Index of Speed and Pen-Pressure of Sketching a Spiral, by Zham et al.](https://www.frontiersin.org/articles/10.3389/fneur.2017.00435/full), The researchers found that the drawing speed was slower and the pen pressure lower among Parkinson’s patients.\n",
    "- [Images Dataset, NIATS of Federal University of Uberlândia.](http://www.niats.feelt.ufu.br/en/node/81)\n",
    "- [Histogram of Oriented Gradients for Human Detection](https://ieeexplore.ieee.org/document/1467360), HOG is a structural descriptor that will capture and quantify changes in local gradient in the input image. HOG will naturally be able to quantify how the directions of a both spirals and waves change. And furthermore, HOG will be able to capture if these drawings have more of a “shake” to them, as we might expect from a Parkinson’s patient.\n",
    "\n",
    "\n",
    "Parkinson’s disease is a nervous system disorder that affects movement. The disease is progressive and is marked by five different stages (source).\n",
    "\n",
    "- Stage 1: Mild symptoms that do not typically interfere with daily life, including tremors and movement issues on only one side of the body.\n",
    "- Stage 2: Symptoms continue to become worse with both tremors and rigidity now affecting both sides of the body. Daily tasks become challenging.\n",
    "- Stage 3: Loss of balance and movements with falls becoming frequent and common. The patient is still capable of (typically) living independently.\n",
    "- Stage 4: Symptoms become severe and constraining. The patient is unable to live alone and requires help to perform daily activities.\n",
    "- Stage 5: Likely impossible to walk or stand. The patient is most likely wheelchair bound and may even experience hallucinations.\n",
    "\n",
    "While Parkinson’s cannot be cured, early detection along with proper medication can significantly improve symptoms and quality of life, making it an important topic as computer vision and machine learning practitioners to explore.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introtroduction\n",
    "---\n",
    "A 2017 study by [Zham et al.](https://www.frontiersin.org/articles/10.3389/fneur.2017.00435/full) found that it was possible to detect Parkinson’s by asking the patient to draw a spiral and then track:\n",
    "\n",
    "1. Speed of drawing\n",
    "- Pen pressure\n",
    "\n",
    "The researchers found that the drawing speed was slower and the pen pressure lower among Parkinson’s patients — this was especially pronounced for patients with a more acute/advanced forms of the disease.\n",
    "\n",
    "**Dataset** \n",
    "is availed by  [Adriano de Oliveira Andrade and Joao Paulo Folado from the NIATS of Federal University of Uberlândia](http://www.niats.feelt.ufu.br/en/node/81), which consists of 204 images and is pre-split into a training set and a testing set, consisting of:\n",
    "\n",
    "1. Spiral: 102 images, 72 training, and 30 testing\n",
    "- Wave: 102 images, 72 training, and 30 testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage import feature,exposure\n",
    "from imutils import build_montages\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[HOG](https://ieeexplore.ieee.org/document/1467360) is a structural descriptor that will capture and quantify changes in local gradient in the input image. HOG will naturally be able to quantify how the directions of a both spirals and waves change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.hog?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_image(image):\n",
    "     # compute the histogram of oriented gradients feature vector for\n",
    "     # the input image\n",
    "     features = feature.hog(image, orientations=9,\n",
    "          pixels_per_cell=(10, 10), cells_per_block=(2, 2),\n",
    "          transform_sqrt=True, block_norm=\"L1\")\n",
    "\n",
    "     # return the feature vector\n",
    "     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "img1=\"dataset/spiral/testing/healthy/V01HE01.png\"\n",
    "img2=\"dataset/spiral/testing/parkinson/V01PE01.png\"\n",
    "img = cv2.imread(img1)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.resize(img, (200, 200))\n",
    "ax = fig.add_subplot(1, 2, 1, xticks=[], yticks=[])\n",
    "ax.imshow(img)\n",
    "img0 = cv2.imread(img2)\n",
    "img0 = cv2.cvtColor(img0, cv2.COLOR_BGR2GRAY)\n",
    "img0 = cv2.resize(img0, (200, 200))\n",
    "ax = fig.add_subplot(1, 2, 2, xticks=[], yticks=[])\n",
    "ax.imshow(img0)\n",
    "plt.xticks([]), plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The thresholding step segments the drawing from the input image, \n",
    "# making the drawing appear as white foreground on a black background\n",
    "image = cv2.threshold(img, 0, 255,\n",
    "               cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantify the image by 12996-features\n",
    "features = quantify_image(image)\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(H, hogImage) = feature.hog(image, orientations=9, pixels_per_cell=(10, 10),\n",
    "                   cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L1\",\n",
    "                   visualise=True)\n",
    "hogImage = exposure.rescale_intensity(hogImage, out_range=(0, 255))\n",
    "hogImage = hogImage.astype(\"uint8\")\n",
    " \n",
    "plt.imshow(hogImage)\n",
    "plt.xticks([]), plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(path):\n",
    "     # grab the list of images in the input directory, then initialize\n",
    "     # the list of data (i.e., images) and class labels\n",
    "     imagePaths = list(paths.list_images(path))\n",
    "     data = []\n",
    "     labels = []\n",
    "\n",
    "     # loop over the image paths\n",
    "     for imagePath in tqdm(imagePaths):\n",
    "          # extract the class label from the filename\n",
    "          label = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "          # load the input image, convert it to grayscale, and resize\n",
    "          # it to 200x200 pixels, ignoring aspect ratio\n",
    "          image = cv2.imread(imagePath)\n",
    "          image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "          image = cv2.resize(image, (200, 200))\n",
    "\n",
    "          # threshold the image such that the drawing appears as white\n",
    "          # on a black background\n",
    "          image = cv2.threshold(image, 0, 255,\n",
    "               cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "          # quantify the image\n",
    "          features = quantify_image(image)\n",
    "\n",
    "          # update the data and labels lists, respectively\n",
    "          data.append(features)\n",
    "          labels.append(label)\n",
    "\n",
    "     # return the data and labels\n",
    "     return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the training and testing directories\n",
    "trainingPath =\"dataset/spiral/training\"\n",
    "testingPath = \"dataset/spiral/testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading data...\")\n",
    "(trainX, trainY) = load_split(trainingPath)\n",
    "(testX, testY) = load_split(testingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels as integers\n",
    "le = LabelEncoder()\n",
    "trainY = le.fit_transform(trainY)\n",
    "testY = le.transform(testY)\n",
    "\n",
    "# initialize our trials dictionary\n",
    "trials = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the number of trials to run\n",
    "ntrials=5\n",
    "for i in tqdm_notebook(range(0, ntrials)):\n",
    "     # train the model\n",
    "     print(\"[INFO] training model {} of {}...\".format(i + 1,ntrials))\n",
    "     model = RandomForestClassifier(n_estimators=100)\n",
    "     model.fit(trainX, trainY)\n",
    "\n",
    "     # make predictions on the testing data and initialize a dictionary\n",
    "     # to store our computed metrics\n",
    "     predictions = model.predict(testX)\n",
    "     metrics = {}\n",
    "\n",
    "     # compute the confusion matrix and and use it to derive the raw\n",
    "     # accuracy, sensitivity, and specificity\n",
    "     cm = confusion_matrix(testY, predictions).flatten()\n",
    "     (tn, fp, fn, tp) = cm\n",
    "     metrics[\"acc\"] = (tp + tn) / float(cm.sum())\n",
    "     metrics[\"sensitivity\"] = tp / float(tp + fn)\n",
    "     metrics[\"specificity\"] = tn / float(tn + fp)\n",
    "\n",
    "     # loop over the metrics\n",
    "     for (k, v) in metrics.items():\n",
    "          # update the trials dictionary with the list of values for\n",
    "          # the current metric\n",
    "          l = trials.get(k, [])\n",
    "          l.append(v)\n",
    "          trials[k] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmo=confusion_matrix(testY, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "df_cm = pd.DataFrame(cmo, range(2),\n",
    "                  range(2))\n",
    "#plt.figure(figsize = (10,7))\n",
    "\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})# font size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over our metrics\n",
    "for metric in (\"acc\", \"sensitivity\", \"specificity\"):\n",
    "     # grab the list of values for the current metric, then compute\n",
    "     # the mean and standard deviation\n",
    "     values = trials[metric]\n",
    "     mean = np.mean(values)\n",
    "     std = np.std(values)\n",
    "\n",
    "     # show the computed metrics for the statistic\n",
    "     print(metric)\n",
    "     print(\"=\" * len(metric))\n",
    "     print(\"𝝁={:.4f}, 𝝈={:.4f}\".format(mean, std))\n",
    "     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select a few images and then initialize the output images\n",
    "# for the montage\n",
    "testingPaths = list(paths.list_images(testingPath))\n",
    "idxs = np.arange(0, len(testingPaths))\n",
    "idxs = np.random.choice(idxs, size=(25,), replace=False)\n",
    "images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the testing samples\n",
    "for i in idxs:\n",
    "     # load the testing image, clone it, and resize it\n",
    "     image = cv2.imread(testingPaths[i])\n",
    "     output = image.copy()\n",
    "     output = cv2.resize(output, (128, 128))\n",
    "\n",
    "     # pre-process the image in the same manner we did earlier\n",
    "     image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "     image = cv2.resize(image, (200, 200))\n",
    "     image = cv2.threshold(image, 0, 255,\n",
    "          cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "     # quantify the image and make predictions based on the extracted\n",
    "     # features using the last trained Random Forest\n",
    "     features = quantify_image(image)\n",
    "     preds = model.predict([features])\n",
    "     label = le.inverse_transform(preds)[0]\n",
    "\n",
    "     # draw the colored class label on the output image and add it to\n",
    "     # the set of output images\n",
    "     color = (255, 0, 0) if label == 'parkinson' else (0, 0, 255)\n",
    "       \n",
    "     cv2.putText(output, label, (3, 20),cv2.FONT_HERSHEY_SIMPLEX , 0.5,color, 2)\n",
    "     images.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a montage using 128x128 \"tiles\" with 5 rows and 5 columns\n",
    "montage = build_montages(images, (128, 128), (5, 5))[0]\n",
    "\n",
    "# show the output montage\n",
    "cv2.imshow(\"Output\", montage)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(montage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
