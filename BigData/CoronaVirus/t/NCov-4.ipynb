{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of NCOPID-19 Data\n",
    "One of the reasons of Python, such populay by ML developers, is its visualization utilities:\n",
    "- Matplotlib, provides the basic functions and utilities to make visualization;\n",
    "- seaborn provides high-level interface for drawing  informative statistical graphics;\n",
    "- plotly, it could not be absent of creating both on-line and off-line visualizations with hand-on interact.\n",
    "\n",
    "Furthermore, python never let you down if animation, dashboard setup are required; try `moviepy, ipywidget, dash, etc`.\n",
    "\n",
    "**Note**. Installing or updating the Python package, you could do it as follows:\n",
    "\n",
    "```\n",
    " shell > pip install -U plotly\n",
    "   or\n",
    " shell > conda install plotly\n",
    "```\n",
    "**Exercise**: install plotly as above.\n",
    "\n",
    "\n",
    "## Data Prepatation\n",
    "In last week practicing, we had learn how to work on the time series data from [JUH](https://github.com/CSSEGISandData/COVID-19). Now create today practicing, NCov-2.ipynb, as follows:\n",
    "\n",
    "```\n",
    "        COVID-19-master/\n",
    "           csse_covid_19_data/\n",
    "           ...        \n",
    "        t/\n",
    "           NCov-1.ipynb\n",
    "           NCov-2.ipynb\n",
    "           ...\n",
    "           tmp/\n",
    "``` \n",
    "In this practicing, the daily data would be used, but not time-series data.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "import os.path\n",
    "from datetime import datetime, date, time \n",
    "from time import strftime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "# use to parse the data timestamp\n",
    "from dateutil.parser import parse\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What day is today\n",
    "str(datetime.date(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/03-20-2020.csv')\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us to look at the last daily data:\n",
    "```\n",
    "Province/State,Country/Region,Last Update,Confirmed,Deaths,Recovered,Latitude,Longitude\n",
    "Hubei,Mainland China,<span class=\"burk\">2020-03-08</span>T<span class=\"girk\">14:43:03</span>,67707,2986,45235,30.9756,112.2707\n",
    ",Italy,2020-03-08T18:03:04,7375,366,622,43.0000,12.0000\n",
    ",South Korea,2020-03-08T12:53:03,7314,50,118,36.0000,128.0000\n",
    ",Iran,2020-03-08T11:03:30,6566,194,2134,32.0000,53.0000\n",
    "Guangdong,Mainland China,2020-03-08T14:43:03,1352,7,1256,23.3417,113.4244  \n",
    "...\n",
    "```\n",
    "1. **the first line**: the name of each column;\n",
    "- **from second line**, each data was recorded as one line and each column was seperted by comma symbol '`,`';\n",
    "-  data in `Last Update`, the 4th column, were in standard datetime format, `Year-month-date time`, where `T` means white space; lately, use the following to parse the data and get `date` and `time`: \n",
    "\n",
    "<table style=\"width: 100%\">\n",
    "      <tbody><tr>\n",
    "        <td style=\"text-align: center; padding-left: 0em; padding-right: 0em\"><table style=\"display: inline-table; vertical-align: middle\">\n",
    "          <tbody><tr>\n",
    "            <td><span style=\"margin-left: 2em\"></span>[0]</td>\n",
    "            <td></td>\n",
    "            <td><span style=\"margin-left: 1em\"></span>[1]</td>\n",
    "          </tr><tr>\n",
    "            <td><font color=\"red\">2020-03-08</font></td>\n",
    "            <td>T</td>\n",
    "            <td><font color=\"blue\">14:43:03</font></td>\n",
    "          </tr><tr>\n",
    "            <td><span style=\"margin-left: 2em\"></span><font color=\"red\">date</font></td>\n",
    "            <td></td>\n",
    "            <td><span style=\"margin-left: 1em\"></span><font color=\"blue\">time</font></td>\n",
    "          </tr></tbody>\n",
    "        </table></td>\n",
    "      </tr><tr>\n",
    "        <td style=\"text-align: center; padding-left: 0em; padding-right: 0em; height: 0.5em\"></td>\n",
    "      </tr></tbody>\n",
    "    </table>\n",
    "\n",
    "\n",
    "\n",
    "   ```\n",
    "   date=parse(str(last_update).split(' ')[0]).strftime(\"%Y-%m-%d\")\n",
    "   time=parse(str(last_update).split(' ')[1]).strftime(\"%Y-%m-%d\")\n",
    "   ```\n",
    "- the first column in third row is in blank which means being omitted generally; it is `NaN` in Pandas.\n",
    "\n",
    "Now load the csv data into worksheet by pandas as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "\n",
    "def clean_sheet_names(new_ranges):\n",
    "    '''\n",
    "    Get rid of the duplicate sheets, only take the sheets from the \n",
    "    latest point in the day\n",
    "    '''\n",
    "    indices = []\n",
    "    \n",
    "    # Remove all sheets that dont have a numeric header\n",
    "    numeric_sheets = [x for x in new_ranges if re.search(r'\\d', x)]  \n",
    "    \n",
    "    return numeric_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv files in \n",
    "\n",
    "     ../COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/\n",
    "\n",
    "and beginning with a numeric character are data but `README.md` and `.gitignore` are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets = os.listdir(DATA)\n",
    "\n",
    "# Clean the result to the sheet tabs we want\n",
    "cleaned_sheets = clean_sheet_names(sorted(sheets, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For assigning date by the time sheet name\n",
    "'''\n",
    "\n",
    "def clean_last_updates(last_update):\n",
    "    date = parse(str(last_update).split(' ')[0]).strftime(\"%Y-%m-%d\")\n",
    "    time = parse(str(last_update).split(' ')[1]).strftime('%H:%M:%S')\n",
    "    parsed_date = str(date) + ' ' + str(time)\n",
    "\n",
    "    return parsed_date\n",
    "\n",
    "def get_date(last_update):\n",
    "    return parse(str(last_update).split(' ')[0]).strftime(\"%Y-%m-%d\")\n",
    "def get_csv_date(file):\n",
    "    return get_date(file.split('.')[0] + ' ') \n",
    "\n",
    "def drop_duplicates(df_):\n",
    "    '''\n",
    "    Take the max date value for each province for a given date\n",
    "    '''\n",
    "    days_list = []\n",
    "    \n",
    "    for datetime in df_.Date.unique():\n",
    "        tmp_df = df_[df_.Date == datetime]\n",
    "        tmp_df = tmp_df.sort_values(['Last Update']).drop_duplicates('Province/State', keep='last')\n",
    "        days_list.append(tmp_df)\n",
    "\n",
    "    return days_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=cleaned_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[0]>'02-21-2020.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.read_csv(os.path.join(DATA, '03-22-2020.csv'), index_col=None, header=0, parse_dates=['Last_Update'])\n",
    "tmp_df.rename(columns={\"Last_Update\": \"Last Update\"},inplace=True) \n",
    "tmp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['Confirmed', 'Country/Region', 'Deaths', 'Last Update', 'Province/State', 'Recovered']\n",
    "numeric_cols = ['Confirmed', 'Deaths', 'Recovered']\n",
    "\n",
    "def get_data(cleaned_sheets):\n",
    "    all_csv = []\n",
    "    # Import all CSV's\n",
    "    #for file in sorted(sheets):\n",
    "    for file in tqdm(sorted(sheets), desc='... importing data: '):    \n",
    "        if 'csv' in file:\n",
    "            #print( file)\n",
    "            if (file>'03-21-2020.csv'):\n",
    "                Last_Date='Last_Update'\n",
    "            else:\n",
    "                Last_Date='Last Update'\n",
    "            tmp_df = pd.read_csv(os.path.join(DATA, file), index_col=None, header=0, parse_dates=[Last_Date])\n",
    "            if (file>'03-21-2020.csv'):\n",
    "               tmp_df.rename(columns={\"Last_Update\": \"Last Update\",'Country_Region':'Country/Region', 'Province_State': 'Province/State'},inplace=True) \n",
    "            \n",
    "            tmp_df = tmp_df[keep_cols]\n",
    "            tmp_df[numeric_cols] = tmp_df[numeric_cols].fillna(0)\n",
    "            tmp_df[numeric_cols] = tmp_df[numeric_cols].astype(int)\n",
    "            tmp_df['Province/State'].fillna(tmp_df['Country/Region'], inplace=True)\n",
    "            #  tmp_df['Last_Update'] = tmp_df['Last_Update'].apply(clean_last_updates)\n",
    "            #else:\n",
    "            #   tmp_df['Last Update'] = tmp_df['Last Update'].apply(clean_last_updates)\n",
    "            tmp_df['Date'] = tmp_df['Last Update'].apply(get_date)\n",
    "            tmp_df['file_date'] = get_csv_date(file)\n",
    "            all_csv.append(tmp_df)\n",
    "\n",
    "    df_ = pd.concat(all_csv, axis=0, ignore_index=True, sort=True)\n",
    "    df_ = df_.sort_values(by=['Last Update'])\n",
    "\n",
    "    #Get the last entry per region by date\n",
    "    frames = drop_duplicates(df_)\n",
    "    tmp = pd.concat(frames, axis=0, ignore_index=True, sort=True)\n",
    "    print(\"\\nData contenance complete, total %d daily data used...\" % len(sheets))\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "df = get_data(cleaned_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have all the data we now need to clean it \n",
    "# - Fill null values\n",
    "# - remore suspected values\n",
    "# - change column names\n",
    "def clean_data(tmp_df):\n",
    "    if 'Demised' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Demised':'Deaths'}, inplace=True)\n",
    "\n",
    "    if 'Country/Region' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Country/Region':'country'}, inplace=True)\n",
    "    \n",
    "    if 'Province/State' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Province/State':'province'}, inplace=True)\n",
    "        \n",
    "    if 'Last Update' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Last Update':'datetime'}, inplace=True)\n",
    "        \n",
    "    if 'Suspected' in tmp_df.columns:\n",
    "        tmp_df = tmp_df.drop(columns='Suspected')\n",
    "\n",
    "    for col in tmp_df.columns:\n",
    "        tmp_df[col] = tmp_df[col].fillna(0)\n",
    "    \n",
    "    #Lower case all col names\n",
    "    tmp_df.columns = map(str.lower, tmp_df.columns) \n",
    "    return tmp_df\n",
    "\n",
    "df  = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = list(map(lambda x:x.lower().strip(), set(df.country.values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import get_close_matches\n",
    "\n",
    "COUNTRY = 'taiwan*'\n",
    "\n",
    "def get_similar_countries(c, country_list):\n",
    "    pos_countries = get_close_matches(c, country_list)\n",
    "    \n",
    "    if len(pos_countries) > 0:\n",
    "        print(c, 'was not listed. did you mean', pos_countries[0].capitalize() + '?')\n",
    "        sys.exit()\n",
    "    else:\n",
    "        print(c, 'was not listed.')\n",
    "        sys.exit()\n",
    "        \n",
    "def check_specified_country(df):\n",
    "    if COUNTRY:\n",
    "        print('Country specified')\n",
    "        if COUNTRY.lower() == 'china':\n",
    "            print(COUNTRY, 'was not listed. did you mean Mainland China?')\n",
    "            \n",
    "        elif COUNTRY.lower() not in country_list:\n",
    "            get_similar_countries(COUNTRY, country_list)\n",
    "            \n",
    "        else:\n",
    "            print('... filtering data for', COUNTRY)\n",
    "            if len(COUNTRY) == 2:\n",
    "                df = df[df.country == COUNTRY.upper()]\n",
    "            else:\n",
    "                df = df[df.country == COUNTRY.capitalize()]\n",
    "            return df\n",
    "    else:\n",
    "        print('No specific country specified')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = check_specified_country(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheets need to be sorted by date value\n",
    "print('Sorting by datetime...')\n",
    "current_date = str(datetime.date(datetime.now()))\n",
    "\n",
    "if df.date.max() == current_date:\n",
    "    df = df[df.date != df.date.max()]\n",
    "else:\n",
    "    df = df[df.date != current_date]\n",
    "\n",
    "df = df.sort_values('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the difference of the sum totals for each\n",
    "date and plot them on a trendline graph\n",
    "'''\n",
    "def get_new_cases(tmp, col):\n",
    "    diff_list = []\n",
    "    tmp_df_list = []\n",
    "    df = tmp.copy()\n",
    "\n",
    "    for i, day in enumerate(df.sort_values('date').date.unique()):    \n",
    "        tmp_df = df[df.date == day]\n",
    "        tmp_df_list.append(tmp_df[col].sum())\n",
    "        \n",
    "        if i == 0:\n",
    "            diff_list.append(tmp_df[col].sum())\n",
    "        else:\n",
    "            diff_list.append(tmp_df[col].sum() - tmp_df_list[i-1])\n",
    "        \n",
    "    return diff_list\n",
    "\n",
    "def get_moving_average(tmp, col):\n",
    "    df = tmp.copy()\n",
    "    return df[col].rolling(window=2).mean()\n",
    "\n",
    "def get_exp_moving_average(tmp, col):\n",
    "    df = tmp.copy()\n",
    "    return df[col].ewm(span=2, adjust=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculating dataframe for new cases...')\n",
    "daily_cases_df = pd.DataFrame([])\n",
    "daily_cases_df['new_confirmed_cases'] = get_new_cases(df, 'confirmed')\n",
    "daily_cases_df['new_deaths'] = get_new_cases(df, 'deaths')\n",
    "daily_cases_df['new_recoveries'] = get_new_cases(df, 'recovered')\n",
    "daily_cases_df['date'] = df.date.unique()\n",
    "\n",
    "#Moving average\n",
    "daily_cases_df['confirmed_MA'] = get_moving_average(daily_cases_df, 'new_confirmed_cases')\n",
    "daily_cases_df['deaths_MA'] = get_moving_average(daily_cases_df, 'new_deaths')\n",
    "daily_cases_df['recovered_MA'] = get_moving_average(daily_cases_df, 'new_recoveries')\n",
    "\n",
    "#Exponential moving average\n",
    "daily_cases_df['confirmed_exp_MA'] = get_exp_moving_average(daily_cases_df, 'new_confirmed_cases')\n",
    "daily_cases_df['deaths_exp_MA'] = get_exp_moving_average(daily_cases_df, 'new_deaths')\n",
    "daily_cases_df['recovered_exp_MA'] = get_exp_moving_average(daily_cases_df, 'new_recoveries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate the number of people that are ACTUALLY infected on a given day\n",
    "currently infected = sum of people date - (recovored + died)\n",
    "ex: 5 = 10 - (4 - 1)\n",
    "\n",
    "'''\n",
    "current_infected = pd.DataFrame([])\n",
    "current_infected['currently_infected'] = (df.groupby('date').confirmed.sum() - \\\n",
    "                                          (df.groupby('date').deaths.sum() + df.groupby('date').recovered.sum()))\n",
    "current_infected['delta'] = (current_infected['currently_infected'] - df.groupby('date').confirmed.sum())\n",
    "daily_cases_df = pd.merge(daily_cases_df, current_infected, how='outer', on='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new folder, named `data`, here manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create date of extraction folder\n",
    "#data_folder = os.path.join('data', str(datetime.date(datetime.now())))\n",
    "#save_dir = os.path.join(out, data_folder)\n",
    "\n",
    "#if not os.path.exists(save_dir):\n",
    "#    os.system('mkdir -p ' + save_dir)\n",
    "save_dir='data'\n",
    "#print('Creating subdirectory for data...')\n",
    "#print('...', save_dir)\n",
    "\n",
    "print('Saving...')\n",
    "file_name = 'agg_data_{}.parquet.gzip'.format(datetime.date(datetime.now()))\n",
    "df.astype(str).to_parquet(os.path.join(save_dir, file_name), compression='gzip')\n",
    "print('...', file_name)\n",
    "\n",
    "\n",
    "csv_file_name = 'agg_data_{}.csv'.format(datetime.date(datetime.now()))\n",
    "df.astype(str).to_csv(os.path.join(save_dir, csv_file_name))\n",
    "print('...', csv_file_name)\n",
    "\n",
    "\n",
    "daily_cases_file_name = 'trend_{}.csv'.format(datetime.date(datetime.now()))\n",
    "daily_cases_df.astype(str).to_csv(os.path.join(save_dir, daily_cases_file_name))\n",
    "print('...', daily_cases_file_name)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import init_notebook_mode, plot, iplot, download_plotlyjs\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.log1p(df['confirmed']), y=df['file_date'],\n",
    "                    mode='lines+markers',\n",
    "                    name='Confirmed in Log'))\n",
    "fig.add_trace(go.Scatter(x=np.log1p(df['recovered']), y=df['file_date'],\n",
    "                    mode='lines+markers',\n",
    "                    name='Recovered'))\n",
    "\n",
    "plot(fig, filename='NCOVID-19.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
