{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NCOV 2019\n",
    "===\n",
    "\n",
    "Outbreak of Novel Corona Virus, (abbreviated as NCov), at late 2019 should be the important event which affects Data Science widely and deeply, from the basic data collecting and washing, analyzing, model fitting, to the cases estimation,  almost all the knowledge and techniques about data science are used to explore the what and when the epidemic flu could be under control.\n",
    "\n",
    "Steps\n",
    "---\n",
    "In this talk, the main goals of the lecture include how to get the open data, how to so data-washing work, and making simple visualization of data.\n",
    "1. [JHU Main Page](https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html?fbclid=IwAR2mWEw0X_B5jbR0Fm23t2TVJGzVqUY6ok98DzrGLMrMXCR_c5joZV5AdNU#/bda7594740fd40299423467b48e9ecf6), open this link, open [Google driver], and save the data [google sheet] to Google driver; data would be updated everyday.<br>\n",
    "**Note**. \n",
    "  - After the Corona Virus being renamed as \"COVID-19\" by WHO, the updated JHU data could be retrieved from [JUH dashboard](https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6) and [github](https://github.com/CSSEGISandData/COVID-19).\n",
    "  - Since 2020/02/17, some \"NaN\" data (time-series data) in JHU dataset has being modified by 0. \n",
    "- Data structure:\n",
    "  - create sub-directory, named `t`; enter it and also create another sub-folder, named `tmp` within it.\n",
    "      - download JUH data and put it above folder `t`, now the file structure is as follows:\n",
    "        ```\n",
    "        COVID-19-master/\n",
    "           csse_covid_19_data/\n",
    "           ...        \n",
    "        t/\n",
    "           NCov-1.ipynb\n",
    "           ...\n",
    "           tmp/\n",
    "        ```   \n",
    "  - ToDo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many data here\n",
    "!ls ../COVID-19-master/*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after 2020/02/19\n",
    "!ls ../COVID-19-master/csse_covid_19_data/csse_covid_19_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Manipulation Tool, Pandas\n",
    "---\n",
    "A straightforward definition is that time series data includes data points attached to sequential time stamps; the NCOV-19 data is the classical case and recorded by day. `Pandas` was created by `Wes Mckinney` to provide an efficient and flexible tool to work with data set, including time-series data.\n",
    "\n",
    "\n",
    "Up to now, the data collected are full of uncertainty and noise; thus, we only make survey of data come from John Hopkins University, the most reliable set. The data had been clean to be much readable and friendly to process further. In the sub-folder, *time_series*, data had been also divided into three catgories, Confirmed, Deaths, and Recovered as they represent actually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the confirmed data for instance:\n",
    "csvfile=\"../COVID-19-master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv\"\n",
    "\n",
    "df=pd.read_csv(csvfile,index_col='Province/State')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV Format\n",
    "---\n",
    "The data is in plain txt format, and named just as what it looks like `Comma Separated Values` (also known as CSV):\n",
    "<img src=\"../imgs/csv.png\" width=90% />\n",
    "1. the first line decribes what the data are: features are seperated by comma symbol;\n",
    "- from the second line, each case was recorded line by line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract of the Dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**{*Note*}, Before 2020/02/19** \n",
    "   \n",
    "   In brief, the first three features are about location data, and the left are the number of occurences; obviously, the numbers should be in integer format and `NaN` means no occurence reported. \n",
    "\n",
    "**After** \n",
    "   \n",
    "   The \"NaN\" data had been corrected. \n",
    "\n",
    "As usual, let us to clean the data to be reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.index.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo's\n",
    "---\n",
    "1. Obviously, the part of cases occured at Diamond Princess is a big problem; all the cases belong to the Japanese occurences, the host of cruise, without doubt; but the effct after travelers back to their countries have to delist from Japan or not.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the dates from the dataframe\n",
    "dates=list(df.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some data is null, (with NaN):\n",
    "df.iloc[:2,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some NaN in index, i.e. `Province/State`\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Washing\n",
    "1. replace Nan column by 0 (no more require);\n",
    "- reset data format of number of occurences, from float to integer (no more require);\n",
    "- Replace `Province/state`-index of `Date`-index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(df)):\n",
    "df['PS']=np.where(df.index.isnull(),df['Country/Region'],df.index)\n",
    "df.set_index('PS')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate \"NaN\" - index\n",
    "def index_fillna(df_,f='Country/Region'):\n",
    "    \"\"\"\n",
    "    replace the NaN in Index by the value in f-fature\n",
    "    \"\"\"\n",
    "    # duplicate DataFrame\n",
    "    df1=df_.copy()\n",
    "    # make a new feature\n",
    "    df1['new']=np.where(df1.index.isnull(),df1['Country/Region'],df1.index)\n",
    "\n",
    "    # reset index with non-NaN values\n",
    "    df1.index=df1['new'].values\n",
    "    # delete the new-feature\n",
    "    df1=df1.drop('new', axis=1)\n",
    "    df1.index.name='Province/State'\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct \"NaN\" index\n",
    "df_s=index_fillna(df)\n",
    "df_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose the data\n",
    "\n",
    "**Replace `Province/state`-index of `Date`-index**\n",
    "\n",
    "Generally, time-series data uses index to represent datetime in Pandas Application. \n",
    "\n",
    "Thus, transpose the data by index of data (cities) to columns, and inversely columns (date time) to index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cities\n",
    "cities=list(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete un\n",
    "df_f=df_s.transpose().iloc[3:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Althought the index is in datetime format, but pandas loaded data by `object` format not datetime: correct, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.index = pd.to_datetime(df_f.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the Index's name\n",
    "df_f.index.name='Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization\n",
    "---\n",
    "Python provides many versatile visualization packages, from static to animation, even interaction functionality is supported.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some display-style by matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"NCOVID-19\",size=16)\n",
    "for r in ['Anhui','Beijing']:\n",
    "   plt.plot(df_f[r],label=r)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simpler...\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f[['Anhui','Beijing']].plot(figsize=[12,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practices and Exercises\n",
    "---\n",
    "1. Get the last data of NCOP. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
