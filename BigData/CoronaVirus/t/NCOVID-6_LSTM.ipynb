{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subjest\n",
    "===\n",
    "Use LSTM scheme to predict the future. Create a new directory, named \"model\", in which the trained model should be stored here.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Requirements\n",
    "---\n",
    "1. warktermark, An IPython magic extension for printing date and time stamps, version numbers, and hardware information. (install by pip)\n",
    "- tensorflow\n",
    "- keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p tensorflow,sklearn,keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name='../COVID-19-master/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "url = dir_name+\"/time_series_covid19_confirmed_global.csv\"\n",
    "df_confirmed = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confirmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"Taiwan*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the data\n",
    "df_confirmed1 = df_confirmed[df_confirmed[\"Country/Region\"] == country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## structuring times eries data\n",
    "df_confirmed2 = pd.DataFrame(df_confirmed1[df_confirmed1.columns[4:]].sum(),columns=[\"confirmed\"])\n",
    "df_confirmed2.index = pd.to_datetime(df_confirmed2.index)#,format='%m/%d/%y')\n",
    "df_confirmed2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for cases of dead\n",
    "\n",
    "df_dead = pd.read_csv(dir_name+\"time_series_covid19_deaths_global.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dead1 = df_dead[df_dead[\"Country/Region\"] == country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dead2 = pd.DataFrame(df_dead1[df_dead1.columns[4:]].sum(),columns=[\"dead\"])\n",
    "df_dead2.index = pd.to_datetime(df_dead2.index)#,format='%m/%d/%y')\n",
    "df_dead2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for cases of recovered\n",
    "df_recovered = pd.read_csv(dir_name+\"time_series_covid19_recovered_global.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered1 = df_recovered[df_recovered[\"Country/Region\"] == country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered2 = pd.DataFrame(df_recovered1[df_recovered1.columns[4:]].sum(),columns=[\"recovered\"])\n",
    "df_recovered2.index = pd.to_datetime(df_recovered2.index)#,format='%m/%d/%y')\n",
    "df_recovered2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## join confirmed with dead\n",
    "df_conf_dead = df_confirmed2.join(df_dead2,how = \"inner\")\n",
    "df_conf_dead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## join confirmed+dead with recovered\n",
    "df_all = df_conf_dead.join(df_recovered2,how = \"inner\")\n",
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.plot(figsize=(10,5),title=\"COVID-19 statistics at %s\" %country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# up to 2020-04-06\n",
    "df_new = df_confirmed2[[\"confirmed\"]]\n",
    "df_new.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily data and i want to predict 5 days afterwards\n",
    "len(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = len(df_new)-5\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df_new.iloc[:x]\n",
    "test = df_new.iloc[x:]\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data ranges too wide to keep stationary; one of the methods is to convert them among `[0,1]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##scale or normalize data as the data is too skewed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train) #find max value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = scaler.transform(train)#and divide every point by max value\n",
    "scaled_test = scaler.transform(test)\n",
    "print(scaled_train[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scaled_train)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feed in batches [t1,t2,t3] --> t4\n",
    "##                 [conf,dead,recov]  --> confirm-predict\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how to decide num of inputs , \n",
    "n_input = 5  ## number of steps\n",
    "n_features = 1 ## number of features you want to predict (for univariate time series n_features=1)\n",
    "generator = TimeseriesGenerator(scaled_train,scaled_train,length = n_input,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#62\n",
    "len(scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#57\n",
    "len(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 50-th pair\n",
    "x,y = generator[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## above takes 5 inputs and predicts next point in scaled_train\n",
    "## smaller batch size leads to better trainig for time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "LSTM:  Long Short Term Memory Networks (LSTM) models           \n",
    "\n",
    "           150 neurons      75 neurons      1 neuron\n",
    "  input ➨    LSTM       ➨   Dense Layer  ➨  output  \n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(150,activation=\"relu\",input_shape=(n_input,n_features)))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeseriesGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = np.append(scaled_train[60],scaled_test)\n",
    "validation_set=validation_set.reshape(6,1)\n",
    "validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how to decide num of inputs , \n",
    "n_input = 5\n",
    "n_features = 1\n",
    "validation_gen = TimeseriesGenerator(validation_set,validation_set,length=5,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_gen[0][0].shape,validation_gen[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=20,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator,validation_data=validation_gen,epochs=100,callbacks=[early_stop],steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.history.history).plot(title=\"loss vs epochs curve\",figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myloss = model.history.history[\"val_loss\"]\n",
    "plt.title(\"validation loss vs epochs\")\n",
    "plt.plot(range(len(myloss)),myloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluation batch\n",
    "## 5 history steps ---> step 6\n",
    "## last 5 point train predicts point 1 of test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## holding predictions\n",
    "test_prediction = []\n",
    "\n",
    "##last n points from training set\n",
    "first_eval_batch = scaled_train[-n_input:]\n",
    "current_batch = first_eval_batch.reshape(1,n_input,n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how far in future we can predict\n",
    "for i in range(len(test)+7):\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "    test_prediction.append(current_pred)\n",
    "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### inverse scaled data\n",
    "true_prediction = scaler.inverse_transform(test_prediction)\n",
    "true_prediction[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_array = test.index\n",
    "for k in range(0,7):\n",
    "    time_series_array = time_series_array.append(time_series_array[-1:] + pd.DateOffset(1))\n",
    "time_series_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not yet input \n",
    "df_forecast = pd.DataFrame(columns=[\"confirmed\",\"confirmed_predicted\"],index=time_series_array)\n",
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast.loc[:,\"confirmed_predicted\"] = true_prediction[:,0]\n",
    "df_forecast.loc[:,\"confirmed\"] = test[\"confirmed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.ylim([80000,85000])\n",
    "df_forecast.plot(figsize=(10,6),title=\"%s Predictions for next 7 days\" %country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE = np.mean(np.abs(np.array(df_forecast[\"confirmed\"][:5]) - np.array(df_forecast[\"confirmed_predicted\"][:5]))/np.array(df_forecast[\"confirmed\"][:5]))\n",
    "print(\"MAPE is \" + str(MAPE*100) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_errs = np.sum((np.array(df_forecast[\"confirmed\"][:5]) - np.array(df_forecast[\"confirmed_predicted\"][:5]))**2)\n",
    "sum_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdev = np.sqrt(1/(5-2) * sum_errs)\n",
    "stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate prediction interval\n",
    "interval = 1.96 * stdev\n",
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast[\"confirm_min\"] = df_forecast[\"confirmed_predicted\"] - interval\n",
    "df_forecast[\"confirm_max\"] = df_forecast[\"confirmed_predicted\"] + interval\n",
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast[\"Model Accuracy\"] = round((1-MAPE),2)\n",
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df_forecast[\"Country\"] = country\n",
    "df_forecast[\"Execution date\"] = str(datetime.now()).split()[0]\n",
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_forecast.to_excel(\"output/Iran_confirmed.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save model\n",
    "model.save(\"model/confirmed_{0}_{1}.h5\".format(country,str(datetime.now()).split()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast.iloc[:,:4].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(10,5))\n",
    "plt.title(\"{} - Results\".format(country))\n",
    "plt.plot(df_forecast.index,df_forecast[\"confirmed\"],label=\"confirmed\")\n",
    "plt.plot(df_forecast.index,df_forecast[\"confirmed_predicted\"],label=\"confirmed_predicted\")\n",
    "#ax.fill_between(x, (y-ci), (y+ci), color='b', alpha=.1)\n",
    "plt.fill_between(df_forecast.index,df_forecast[\"confirm_min\"],df_forecast[\"confirm_max\"],color=\"indigo\",alpha=0.09,label=\"Confidence Interval\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "name = \"model/confirmed_{0}_{1}.h5\".format(country,str(datetime.now()).split()[0])\n",
    "model1 = load_model(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
