{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Santander Fast Compact Solution](https://www.kaggle.com/gpreda/santander-fast-compact-solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('input/train.csv')\n",
    "test_df = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features\n",
    "---\n",
    "1. target, predicted feature\n",
    "2. var_n, b=0, ...,199, 200 given features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature=['target']\n",
    "var_features=train_df.columns.tolist()[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_plot(df,m=0,n=3):\n",
    "    df[var_features[m:n+1]].hist(figsize=[12,6])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot(df,m=0,n=3):\n",
    "    #visualizing the features w high positive correlation\n",
    "    f, axes = plt.subplots(nrows=1, ncols=n-m+1, figsize=(12,6))\n",
    "\n",
    "    #f.suptitle('Features With  Correlation', size=20)\n",
    "    for i in range(m,n+1):\n",
    "        sns.boxplot(x=\"target\", y=var_features[i], data=df,ax=axes[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_plot(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `var_n` seems to be distributed normally, but not standard normally. Let's to convert them into same level by `sklearn.preprocessing`: \n",
    "1. scale:\n",
    "- normalize\n",
    "- MinMax,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_scale(df,kind='scale'):\n",
    "    f_num=df.select_dtypes(include=[np.number]).columns.tolist()[-200:]\n",
    "    if kind=='scale':\n",
    "       df[f_num]=preprocessing.scale(df[f_num])\n",
    "    if kind=='normalize':\n",
    "       df[f_num]=preprocessing.normalize(df[f_num])\n",
    "    if kind=='minmax':\n",
    "       scaler=preprocessing.MinMaxScaler()\n",
    "       #print( df[f_num].info())\n",
    "       df[f_num]=scaler.fit_transform(df[f_num])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_s\n",
    "train_df_s=df_scale(train_df,kind='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_plot(train_df_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(train_df_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_s=df_scale(test_df,kind='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_plot(test_df_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Scheme\n",
    "---\n",
    "Naïve Bayes is a simple, yet effective and commonly-used, machine learning classifier.\n",
    "\n",
    "1. features, $X_0,X_1,..., X_i, (X_i)$, 200 $\\{X_i\\}$;\n",
    "2. class, $\\{C_i\\}$; here, only one `target`=$C_1$ evaluated with 0 or 1.\n",
    "3. $$ P(C=c_1|X_i=x_i)={P(X_1=x_1,X_2=x_2,\\cdots|C_1=c_1)}{P(C_1=c_1)}=P(C_1=c_1)\\prod_i P (X_i|C_1=c_1)$$\n",
    "4. Naive Bayes simply pick the $c_i$ that has the largest probability given the data point’s features:\n",
    "   $$y= \\text{argmax}_{c_i}P(C_1=c_1)\\prod_i P (X_i|C_1=c_1)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprior to make predict, we have to train the model: \n",
    "1. split data into train and valid sets, one for training and one for model validating;\n",
    "-  What belong to `training` set and what belong to `valid` one? Without loss of generality, choose these two parts randomly.\n",
    "-  Repeat above, and make prediction by each indevidual model. The the average of them would be the one we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train/valid randomly\n",
    "def split_data(df,ratio):\n",
    "    sample=np.random.rand(len(df))<ratio\n",
    "    return(df[sample],df[~sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes first try \n",
    "clf=GaussianNB()\n",
    "ratio=0.6\n",
    "train,test=split_data(train_df_s,ratio)\n",
    "clf.fit(train[var_features],train.target)\n",
    "pred=clf.predict(test[var_features])\n",
    "#pred_acc=sum(test.target==pred)/len(test)\n",
    "pred_acc=np.mean(test.target==pred)\n",
    "print(\" Accuracy %4.3f within %4.2f set.\" %(pred_acc,ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "---\n",
    " Accuracy is more than 92% in valid set, 40% splited from original training set.  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "title_config = {'fontsize': 20, 'y': 1.05}\n",
    "\n",
    "fpr, tpr, thr = roc_curve(train.target, pipeline.predict_proba(train[var_features])[:,1])\n",
    "plt.figure(figsize=[12,6])\n",
    "plt.plot(fpr, tpr)\n",
    "# 1 - Specficity\n",
    "plt.xlabel('False Positive Rate, $FP/(FP+TN)$')\n",
    "# Sensibility\n",
    "plt.ylabel('True Positive Rate, $TP/(TP+FN)$')\n",
    "plt.title('Receiver Operating Characteristic Plot', **title_config)\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_Classify_1(df_train,df_test,folds=5,ratio=0.6):    \n",
    "    df_test_p=df_test[['ID_code']].copy()\n",
    "    for i in range(folds):\n",
    "        print(\"Fold %s\" %i)\n",
    "        train,test=split_data(df_train,ratio)\n",
    "        clf=GaussianNB()\n",
    "        clf.fit(train.drop(['ID_code','target'],axis=1),train.target)\n",
    "        pred=clf.predict(test.drop(['ID_code','target'],axis=1))\n",
    "        pred_acc=np.mean(test.target==pred) \n",
    "        print(\" Accuracy %4.3f within %4.2f set.\" %(pred_acc,ratio))\n",
    "        pre_col='target_'+str(i)\n",
    "        df_test_p[pre_col]=clf.predict(df_test.drop(['ID_code'],axis=1))\n",
    "    return df_test_p   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=NB_Classify_1(train_df_s,test_df_s,folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['target']=sub[sub.columns.to_list()[1:]].mean(axis=1)\n",
    "sub=sub.drop(sub.columns.to_list()[1:-1],axis=1)\n",
    "\n",
    "sub.to_csv(\"output/2019-03-16-NB_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantage from Scikit-learn\n",
    "---\n",
    "We had scaled (transformed) train data set manually. Scikit-learn avails more flexible utilities for EDA, including:\n",
    "1. transform data set,\n",
    "- pipeline supported,\n",
    "- score evaluted,\n",
    "- cross-validate function, \n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train,test=split_data(train_df_s,ratio)\n",
    "X_train=train_df[var_features]\n",
    "y_train=train_df['target']\n",
    "\n",
    "pipeline = make_pipeline(QuantileTransformer(output_distribution='normal'), GaussianNB())\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "title_config = {'fontsize': 20, 'y': 1.05}\n",
    "\n",
    "fpr, tpr, thr = roc_curve(y_train, pipeline.predict_proba(X_train)[:,1])\n",
    "plt.figure(figsize=[12,6])\n",
    "plt.plot(fpr, tpr)\n",
    "# 1 - Specficity\n",
    "plt.xlabel('False Positive Rate, $FP/(FP+TN)$')\n",
    "# Sensibility\n",
    "plt.ylabel('True Positive Rate, $TP/(TP+FN)$')\n",
    "plt.title('Receiver Operating Characteristic Plot', **title_config)\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(pipeline, X_train,y_train, scoring='roc_auc', cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test_df[var_features]\n",
    "submission = pd.read_csv('input/sample_submission.csv')\n",
    "\n",
    "submission['target'] = pipeline.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('output/2019-03-16-NB_pipeline_.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "---\n",
    " Accuracy is more than 92% in valid set, 40% splited from original training set.  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_Classify_1(df_train,df_test,folds=5,ratio=0.6):    \n",
    "    df_test_p=df_test[['ID_code']].copy()\n",
    "    for i in range(folds):\n",
    "        print(\"Fold %s\" %i)\n",
    "        train,test=split_data(df_train,ratio)\n",
    "        clf=GaussianNB()\n",
    "        clf.fit(train.drop(['ID_code','target'],axis=1),train.target)\n",
    "        pred=clf.predict(test.drop(['ID_code','target'],axis=1))\n",
    "        pred_acc=np.mean(test.target==pred) \n",
    "        print(\" Accuracy %4.3f within %4.2f set.\" %(pred_acc,ratio))\n",
    "        pre_col='target_'+str(i)\n",
    "        df_test_p[pre_col]=clf.predict(df_test.drop(['ID_code'],axis=1))\n",
    "    return df_test_p   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=NB_Classify_1(train_df_s,test_df_s,folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.target_0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['target']=sub[sub.columns.to_list()[1:-1]].mean(axis=1)\n",
    "sub=sub.drop(sub.columns.to_list()[1:-1],axis=1)\n",
    "\n",
    "sub.to_csv(\"output/2019-03-16-NB_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_1=pd.read_csv(\"output/submission-1.09-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['target']=sub_1.target*0.8+sub['target']*0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"output/2019-03-16-lgb_0.9_NB_0.1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_1.target.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Questions\n",
    " ---\n",
    " 1. Since the data were splited randomly, is the result always the same? \n",
    "          Redo above repeatedly to get the final prediction\n",
    " -  In this data set, use 200 features, var_0 to vae_199, to predict the output, `target`. As expected, all the features is certainly related with the output more or less; however, is any one noise feature which we can ignore. furthermore, could it be possible to make prediction worse?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
