{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering (FE)\n",
    "===\n",
    "Magic, secret behind the data, would help to classify the true.\n",
    "\n",
    "1. [Classify which ones are true or fake data](#Magic-1,-divide-real-and-fake-test-samples)\n",
    "- [Calculate Counts for each Unique Value](#Magic-frequency-counts)\n",
    "- [Concatenate outputs](#Blend-Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random,gc\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split,cross_validate\n",
    "import os,datetime\n",
    "\n",
    "import warnings,random\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference  the bottom\n",
    "\n",
    "W  = '\\033[0m'  # white (normal)\n",
    "R  = '\\033[31m' # red\n",
    "G  = '\\033[32m' # green\n",
    "O  = '\\033[1;33m' # orange\n",
    "B  = '\\033[34m' # blue\n",
    "P  = '\\033[35m' # purple\n",
    "\n",
    "T =  '\\033[1;33;47m' #Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('input/train.csv')\n",
    "test_df = pd.read_csv('input/test.csv')\n",
    "\n",
    "features=train_df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magics\n",
    "===\n",
    "\n",
    "Magic 1, divide real and fake test samples\n",
    "---\n",
    "\n",
    "```\n",
    "features   f0, f1, f2, ...\n",
    "  data\n",
    "   d0       \n",
    "   d1      ⬇︎\n",
    "   d2\n",
    "   :\n",
    "``` \n",
    "1. Only data, owning unique value, could be real there, otherwise were duplicated for test with large probability, by ```np.unique()```; and save it to ```unique_count = [row × column]```\n",
    "- U = `np.sum(unique_count, axis=1)` gives array of uniques for each data\n",
    "```\n",
    "for instance, U = [ 0, 1, 0, 1       [ 2\n",
    "                    0, 0, 0, 0    ➠     0\n",
    "                    0, 1, 1, 1           3 \n",
    "                    0, 0, 0, 0           0\n",
    "                    ...]               ...]\n",
    "```\n",
    "- `np.argwhere(U > 0)[:, 0]` gives all the indecies of data, owing at least one uniques value.\n",
    "```\n",
    "   [ 2,\n",
    "     0,     ➠ [0,2,...]\n",
    "     3,\n",
    "     0,\n",
    "     ...]    \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(np.sum([[1,2,3],[3,4,5]],axis=1)>6)\n",
    "np.sum([[1,2,3],[3,4,5]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_val_found(data_val):\n",
    "    \"\"\"\n",
    "    input numpy array of data: data_val\n",
    "    output: real_ind, fake_ind \n",
    "    \"\"\"\n",
    "    unique_samples = []\n",
    "    unique_count = np.zeros_like(data_val)\n",
    "    for feature in tqdm_notebook(range(data_val.shape[1])):\n",
    "        # Filter out all the pair of (index,count)\n",
    "        _, index_, count_ = np.unique(data_val[:, feature], return_counts=True, return_index=True)\n",
    "        unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "    # Samples which have unique values are real, or are fake\n",
    "    real_ind = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "    fake_ind = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "    r_n=len(real_ind)\n",
    "    f_n=len(fake_ind)\n",
    "    r_ratio=r_n/data_val.shape[0]\n",
    "    print(\"no. of real samples: %s\\nno. of fake samples: %s\\nratio of real samples: %s\" %(r_n,f_n,r_ratio))\n",
    "    return real_ind,fake_ind\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_=train_df.drop(['ID_code','target'], axis=1).values\n",
    "\n",
    "trn_real_ind,trn_fake_ind=unique_val_found(trn_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_=test_df.drop(['ID_code'], axis=1).values\n",
    "\n",
    "te_real_ind,te_fake_ind=unique_val_found(te_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magic frequency counts\n",
    "---\n",
    "After filtering out true data in test set as above, delete the fake ones; and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_df.columns[2:]\n",
    "\n",
    "X_train=train_df[features].copy()\n",
    "y_train=train_df.target.values\n",
    "X_test = test_df[features].copy()\n",
    "X_real_test = X_test.iloc[te_real_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, X_real_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `df.value_counts()` gives the value (tmp) with frequency as follows:\n",
    "```\n",
    "  feature     frequency\n",
    "     a           n1\n",
    "     b           n2\n",
    "     ...\n",
    "``` \n",
    "2. df.map(tmp) maps value to its frequency; here clip by 6, the biggest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cols = []\n",
    "\n",
    "for c in tqdm_notebook(features[:200]):\n",
    "    count_col = c+'_count'\n",
    "    tmp = pd.concat((X_train[c], X_real_test[c])).value_counts()\n",
    "    # mean of target is small \n",
    "    X_train[count_col] = X_train[c].map(tmp).clip(0, 6)\n",
    "    X_test[count_col] = X_test[c].map(tmp).clip(0, 6).fillna(1)\n",
    "    count_cols.append(count_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_count(train,test,real_test,cut=6):\n",
    "    \"\"\"\n",
    "    input: train,test,real_test, cuts (opt)\n",
    "    output: train,test (with new freq_count features), array of new features\n",
    "    \"\"\"\n",
    "    count_cols = []\n",
    "    features=train.columns\n",
    "    for c in tqdm_notebook(features):\n",
    "        count_col = c+'_count'\n",
    "        tmp = pd.concat((train[c], real_test[c])).value_counts()\n",
    "        # mean of target is small \n",
    "        train[count_col] = train[c].map(tmp).clip(0, cut)\n",
    "        test[count_col] = test[c].map(tmp).clip(0, cut).fillna(1)\n",
    "        count_cols.append(count_col)\n",
    "    print(\"%s features before, %s features after...\" %(len(features),len(train.columns)))   \n",
    "    return train,test,count_cols  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train,XX_test,cols_new=freq_count(X_train,X_test,X_real_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test One\n",
    "---\n",
    "Revisit lightgbm traing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,          \n",
    "    'bagging_fraction': 0.23+0.77,\n",
    "    'bootstrap' :  True,\n",
    "    'bagging_with_replacement' : True,\n",
    "    'boost_from_average':'false',   \n",
    "    'boost': 'gbdt',#'dart',\n",
    "    # The var_count have to be considered together, turn the fraction BE 1!\n",
    "    'feature_fraction': 0.04+0.06+0.9,   \n",
    "    'learning_rate': 0.006,     \n",
    "    'max_depth': -1,\n",
    "    'num_leaves': 64,\n",
    "    'metric':'auc',#'binary_logloss',\n",
    "    'lambda_l1':0.01, \n",
    "    'lambda_l2':0.01*100,\n",
    "    'min_data_in_leaf': 80,     \n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13-10,           \n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    #'max_bin': 40,\n",
    "    'objective': 'binary', \n",
    "    'is_unbalance': 'true',\n",
    "    'verbosity': 1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with Magics\n",
    "num_round = 1000000\n",
    "features_m=X_train.columns.values\n",
    "target=train_df['target']\n",
    "train, test = train_test_split(X_train, test_size=0.2,random_state=random.randint(1,1e5))\n",
    "\n",
    "trn_data=lgb.Dataset(train[features],label=target.iloc[train.index])\n",
    "val_data=lgb.Dataset(test[features],label=target.iloc[test.index])\n",
    "\n",
    "clf=lgb.train(param, trn_data,num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, \n",
    "              early_stopping_rounds = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blend Models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    nfalse = 0\n",
    "    auc = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n):\n",
    "        y_i = y_true[i]\n",
    "        nfalse += (1 - y_i)\n",
    "        auc += y_i * nfalse\n",
    "    auc /= (nfalse * (n - nfalse))\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def individual_ml_model(train,target,test,param=\"\",fname='model'):\n",
    "    # check whether the saved directory exists , create it if not\n",
    "    directory=\"submissions/grouped/\"+fname\n",
    "    nseed=1\n",
    "    if not os.path.exists(directory):\n",
    "       os.makedirs(directory) \n",
    "    \n",
    "    # save result in name of scheme\n",
    "    now = datetime.datetime.now()\n",
    "    now = str(now.strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "    print('started at:', now)\n",
    "    print(\"train set shape: \",train.shape, \", test set shape: \",test.shape)\n",
    "    print(\"Features: \", train.columns.values)\n",
    "    #fname = directory'_'+now\n",
    "    if True:\n",
    "       x_train = train.copy()#[[c, count]].copy()\n",
    "       y_train = target\n",
    "       x_test = test.copy()#[[c, count]].copy()\n",
    "       result=model_lgb(x_train,y_train,x_test,param=param,directory=directory)\n",
    "       # result=model_lgb(x_train,y_train,x_test,param=param,directory=directory)\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lgb(train,target,test,param=\"\",directory=\"submissions/grouped\"):\n",
    "    if not param:\n",
    "       param = {\n",
    "         'bagging_freq': 5,          \n",
    "         'bagging_fraction': 1,\n",
    "         'bootstrap' :  True,\n",
    "         'bagging_with_replacement' : True,\n",
    "         'boost_from_average':'false',   \n",
    "         'boost': 'gbdt',\n",
    "         # The var_count have to be considered together, turn the fraction BE 1!\n",
    "         'feature_fraction': 1,   \n",
    "         'learning_rate': 0.01,     \n",
    "         'max_depth': 2,\n",
    "         'num_leaves': 3,\n",
    "         'metric':'binary_logloss',\n",
    "         'lambda_l1':0.01, \n",
    "         'lambda_l2':2,\n",
    "         'min_data_in_leaf': 80,     \n",
    "         'min_sum_hessian_in_leaf': 10.0,          \n",
    "         'num_threads': 8,\n",
    "         'tree_learner': 'serial',\n",
    "         #'max_bin': 40,\n",
    "         'objective': 'binary', \n",
    "         'verbosity': 1,\n",
    "       }\n",
    "        \n",
    "    num_round = 1000000\n",
    "    features=train.columns.values\n",
    "    target=target\n",
    "                \n",
    "    trn, te_ = train_test_split(train, test_size=0.2,random_state=random.randint(1,1e5))\n",
    "\n",
    "    trn_data=lgb.Dataset(trn[features],label=target.iloc[trn.index])\n",
    "    val_data=lgb.Dataset(te_[features],label=target.iloc[te_.index])\n",
    "\n",
    "    clf=lgb.train(param, trn_data,num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, \n",
    "                 early_stopping_rounds = 500)\n",
    "    train_pred=clf.predict(train[features]) \n",
    "    print('%s train auc: %0.5f' % (features,fast_auc(target, train_pred)), end=' ')\n",
    "    test_pred=clf.predict(test[features])\n",
    "    sub=pd.read_csv(\"input/sample_submission.csv\")\n",
    "    sub['target']=test_pred\n",
    "    saved_fold=directory+\"/\"+c+\".csv\"\n",
    "    sub.to_csv(saved_fold,index=False)\n",
    "\n",
    "    print(\"\\n\\n   *** train/prediction end, output saved as \",directory+\"/\"+c+\".csv\",' ...' )\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "individual_ml_model(X_train,target,X_test,param=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=np.array([])\n",
    "size=len(features)\n",
    "for c, count in zip(tqdm_notebook(features[:size]), count_cols[:size]):\n",
    "    print(T+R+\"(%s,%s) Train/Test\\n\" %(c,count))\n",
    "    print(W+\"===\")\n",
    "    x_train_1 = X_train[[c, count]].copy()\n",
    "    y_train = target\n",
    "    x_test_1 = X_test[[c, count]].copy()\n",
    "    f=individual_ml_model(x_train_1,y_train,x_test_1)\n",
    "    final=np.append(final,f)\n",
    "    print(\"\\n ===\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the submit data\n",
    "final=final.reshape(size,200000)\n",
    "final.mean(axis=0)\n",
    "sub=pd.read_csv(\"input/sample_submission.csv\")\n",
    "sub['target']=final.mean(axis=0)\n",
    "\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"output/late.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 1000000\n",
    "features=train.columns[2:]\n",
    "target=train['target']\n",
    "train, test = train_test_split(train_df, test_size=0.33,random_state=random.randint(1,1e5))\n",
    "\n",
    "trn_data=lgb.Dataset(train[features],label=train['target'])\n",
    "val_data=lgb.Dataset(test[features],label=test['target'])\n",
    "\n",
    "clf=lgb.train(param, trn_data,num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, \n",
    "              early_stopping_rounds = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_m =  {\n",
    "    'boosting_type': 'gbdt',\n",
    "  \"objective\"                  : \"binary\",\n",
    "  \"learning_rate\"              : 0.01,\n",
    "  \"num_leaves\"                 : 3,\n",
    "    'feature_fraction':1,\n",
    "  \"bagging_fraction\"           : 0.8,\n",
    "  \"bagging_freq\"               : 1,\n",
    "               #'min_data_in_leaf' : 80,\n",
    "               #'min_sum_hessian_in_leaf' : 10.0,\n",
    "     'nthread'                  : 20,\n",
    "    'bin_construct_sample_cnt' : 1000000,\n",
    "    'max_depth':2,\n",
    "    'lambda_l2':2,\n",
    "    'metric':'auc',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with Magics\n",
    "num_round = 1000000\n",
    "features_m=X_train.columns.values\n",
    "target=train_df['target']\n",
    "train, test = train_test_split(X_train, test_size=0.2,random_state=random.randint(1,1e5))\n",
    "\n",
    "trn_data=lgb.Dataset(train[features_m],label=target.iloc[train.index])\n",
    "val_data=lgb.Dataset(test[features_m],label=target.iloc[test.index])\n",
    "\n",
    "clf=lgb.train(param, trn_data,num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, \n",
    "              early_stopping_rounds = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with Magics\n",
    "num_round = 1000000\n",
    "features_m=X_train.columns.values\n",
    "target=train_df['target']\n",
    "train, test = train_test_split(X_train, test_size=0.33,random_state=random.randint(1,1e5))\n",
    "\n",
    "trn_data=lgb.Dataset(train[features_m],label=target.iloc[train.index])\n",
    "val_data=lgb.Dataset(test[features_m],label=target.iloc[test.index])\n",
    "\n",
    "clf=lgb.train(param_m, trn_data,num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, \n",
    "              early_stopping_rounds = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred=clf.predict(X_train[features_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(clf, max_num_features=30, importance_type='split',figsize=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
